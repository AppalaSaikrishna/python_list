{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVorost3ocVr1o97rp0eDp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AppalaSaikrishna/python_list/blob/main/18_02_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RZheYGDsefb9"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "url = \"http://quotes.toscrape.com/\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "quotes = soup.find_all(\"div\", class_=\"text\")\n",
        "for quote in quotes:\n",
        "    print(quote.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chck if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        " # Find all quote containers\n",
        "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
        "    # Loop through each quote and extract data\n",
        "    for i, quote in enumerate(quotes[:5]):  # Get first 5 quotes\n",
        "        text = quote.find(\"span\", class_=\"text\").text  # Quote text\n",
        "        author = quote.find(\"small\", class_=\"author\").text  # Author name\n",
        "        tags = [tag.text for tag in quote.find_all(\"a\", class_=\"tag\")]  # List of tags\n",
        "        print(f\"{i+1}. \\\"{text}\\\" - {author}\")\n",
        "        print(f\"   Tags: {', '.join(tags)}\\n\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve the webpage. Status Code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X4pgZIJgH1y",
        "outputId": "68ee03bc-45e1-4a51-e96d-b33bb99e6927"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. \"“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\" - Albert Einstein\n",
            "   Tags: change, deep-thoughts, thinking, world\n",
            "\n",
            "2. \"“It is our choices, Harry, that show what we truly are, far more than our abilities.”\" - J.K. Rowling\n",
            "   Tags: abilities, choices\n",
            "\n",
            "3. \"“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\" - Albert Einstein\n",
            "   Tags: inspirational, life, live, miracle, miracles\n",
            "\n",
            "4. \"“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\" - Jane Austen\n",
            "   Tags: aliteracy, books, classic, humor\n",
            "\n",
            "5. \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\" - Marilyn Monroe\n",
            "   Tags: be-yourself, inspirational\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "# Define the city (e.g., New York)\n",
        "city = \"india/hyderabad\"\n",
        "# Weather URL\n",
        "url = f\"https://www.timeanddate.com/weather/{city}\"\n",
        "# Send GET request\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "# Extract temperature and description\n",
        "temp = soup.find(\"div\", class_=\"h2\").text.strip() if soup.find(\"div\", class_=\"h2\") else \"N/A\"\n",
        "desc = soup.find(\"p\").text.strip() if soup.find(\"p\") else \"N/A\"\n",
        "print(f\"Current Weather in Hyderabad: {temp} | {desc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfA5NREDgVQq",
        "outputId": "acade755-836e-4631-ee36-f80bfd8538f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Weather in Hyderabad: 86 °F | Clear.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "# Product search URL (Example: iPhone)\n",
        "search_url = \"https://www.amazon.in/s?k=iphone&crid=146NZM4AKNRQL&sprefix=%2Caps%2C179&ref=nb_sb_ss_recent_1_0_recent\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "# Send GET request\n",
        "response = requests.get(search_url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "# Extract first product name & price\n",
        "product = soup.select_one(\"span.a-size-medium\")\n",
        "price = soup.select_one(\"span.a-price-whole\")\n",
        "# Display product details\n",
        "if product and price:\n",
        "    print(f\"Product: {product.text.strip()}\")\n",
        "    print(f\"Price: Rs.{price.text.strip()}\")\n",
        "else:\n",
        "    print(\"Could not find product details.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1dX8oaEkRct",
        "outputId": "0f73640b-db97-4a49-80f7-6b928072dc81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not find product details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "# Product search URL (Example: iPhone)\n",
        "search_url = \"https://www.amazon.in/s?k=iphone&crid=146NZM4AKNRQL&sprefix=%2Caps%2C179&ref=nb_sb_ss_recent_1_0_recent\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "# Send GET request\n",
        "response = requests.get(search_url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "# Extract first product name & price\n",
        "product = soup.select_one(\"span.a-size-medium\")\n",
        "price = soup.select_one(\"span.a-price-whole\")\n",
        "# Display product details\n",
        "if product and price:\n",
        "    print(f\"Product: {product.text.strip()}\")\n",
        "    print(f\"Price: Rs.{price.text.strip()}\")\n",
        "else:\n",
        "    print(\"Could not find product details.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrkqPafbkxya",
        "outputId": "9b3141f4-1bf4-499e-f22c-899b3a447453"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not find product details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "# Wikipedia page URL\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\"\n",
        "# Send GET request\n",
        "response = requests.get(url,headers=headers)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "# Find the table\n",
        "table = soup.find(\"table\", class_=\"wikitable\")\n",
        "# Extract the first 5 countries and their population\n",
        "for row in table.find_all(\"tr\")[1:6]:  # Skip the header row\n",
        "    columns = row.find_all(\"td\")\n",
        "    country = columns[1].text.strip()\n",
        "    population = columns[2].text.strip()\n",
        "    print(f\"{country}: {population}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIJZndNuoL1Z",
        "outputId": "ffeb2980-497f-415a-b85f-2c50549c4c6e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "World: 8,119,000,000\n",
            "China: 1,408,280,000\n",
            "1,402,737,000: 17.2%\n",
            "United States: 340,110,988\n",
            "Indonesia: 282,477,584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GcG_AJIQpDRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "TStvjfCWoPsD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display"
      ],
      "metadata": {
        "id": "9qYDNoN4ohD7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}